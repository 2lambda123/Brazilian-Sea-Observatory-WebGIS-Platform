{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler, FileCreatedEvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = os.path.join(os.path.sep, 'home')\n",
    "i_dir = os.path.join(os.path.sep, base, 'vector_speed_forecast_daily')\n",
    "o_dir = os.path.join(os.path.sep, base, 'leaflet_velocity')\n",
    "i_file = os.path.join(os.path.sep, i_dir, \"vector_speed_forecast_daily_1.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime(tdelta):\n",
    "    return (datetime(1950,1,1) + timedelta(hours=tdelta)).strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(variable_data, time=0, depth=0):\n",
    "    v=[]\n",
    "    for lat in reversed(range(1, variable_data.data.shape[2], 12)):\n",
    "        for lon in range(0, variable_data.data.shape[3], 12):\n",
    "            value = variable_data.data[time, depth, lat, lon]\n",
    "            v.append(round(value, 2) if not xr.ufuncs.isnan(value) else 0.)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_to_json(file, variable_name, time, pnumber):\n",
    "    netcdf_data = xr.open_dataset(file)\n",
    "    variable_data = netcdf_data[variable_name]\n",
    "    json_data = {}\n",
    "    json_data['header'] = {}\n",
    "    json_data['header']['dx'] = 1.\n",
    "    json_data['header']['dy'] = 1.\n",
    "    json_data['header']['la1'] = netcdf_data['latitude'].attrs['valid_max']\n",
    "    json_data['header']['la2'] = netcdf_data['latitude'].attrs['valid_min']\n",
    "    json_data['header']['lo1'] = netcdf_data['longitude'].attrs['valid_max']\n",
    "    json_data['header']['lo2'] = netcdf_data['longitude'].attrs['valid_min']\n",
    "    json_data['header']['nx'] = 360\n",
    "    json_data['header']['ny'] = 170\n",
    "    json_data['header']['parameterCategory'] = 2\n",
    "    json_data['header']['parameterNumber'] = pnumber\n",
    "    if (variable_name == 'uo'):\n",
    "        json_data['header']['parameterNumberName'] = 'Eastward current'\n",
    "    else:\n",
    "        json_data['header']['parameterNumberName'] = 'Northward current'\n",
    "    json_data['header']['parameterUnit'] = 'm.s-1'\n",
    "    json_data['header']['refTime'] = pd.to_datetime(time).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    json_data['data'] = get_data(variable_data)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(MyEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netcdf_to_json(file):\n",
    "    data = xr.open_dataset(file)\n",
    "    for time in data['time'].data:\n",
    "        output = []\n",
    "        output.append(variable_to_json(file, 'uo', time, 2))\n",
    "        output.append(variable_to_json(file, 'vo', time, 3))\n",
    "        outfile = os.path.join(os.path.sep, o_dir, pd.to_datetime(time).strftime('%Y-%m-%d') + '.json')\n",
    "        with open(outfile, 'w') as f:\n",
    "            f.write(json.dumps(output, cls=MyEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventHandler(FileSystemEventHandler):\n",
    "    def on_created(self, event):\n",
    "        if isinstance(event, FileCreatedEvent):\n",
    "            netcdf_to_json(event.src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_handler = EventHandler()\n",
    "observer = Observer()\n",
    "observer.schedule(event_handler, i_dir, recursive=True)\n",
    "observer.start()\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    observer.stop()\n",
    "observer.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
